runtime:
  python_version: "3.12"
  endpoints:
    ollama:
      host: "127.0.0.1"
      port: 19134
    vllm:
      host: "127.0.0.1"
      port: 28000
  docs_paths:
    - "/docs"
    - "/redoc"
    - "/openapi.json"

models:
  - id: "qwen-27b-ollama"
    engine: "ollama"
    ollama_model: "qwen3:32b"
    auto_load: true
    enabled: true
    parameters:
      temperature: 0.7
      top_p: 0.9
      num_ctx: 8192
    resource_policy:
      keep_alive: "30m"
      unload_timeout: 60

  - id: "qwen-27b-vllm"
    engine: "vllm"
    vllm_model: "Qwen/Qwen3-8B"
    auto_load: true
    enabled: true
    parameters:
      temperature: 0.7
      top_p: 0.9
      num_ctx: 8192
      dtype: "float16"
      max_model_len: 8192
      tensor_parallel_size: 1
    resource_policy:
      keep_alive: "30m"
      unload_timeout: 60
